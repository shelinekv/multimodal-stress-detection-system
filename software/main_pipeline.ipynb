{"cells":[{"cell_type":"markdown","metadata":{"id":"pfd7z48c-fPQ"},"source":["***CCN*** **Algorithm**"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":373},"id":"UmkYNoI0P03n","outputId":"54fda5ec-2609-48c2-d7a8-dfe242bb9a64","executionInfo":{"status":"error","timestamp":1771568335269,"user_tz":-330,"elapsed":19833,"user":{"displayName":"sheline K V","userId":"14611107045263504625"}}},"outputs":[{"output_type":"error","ename":"MessageError","evalue":"Error: credential propagation was unsuccessful","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-704294643.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 97\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m     98\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    132\u001b[0m   )\n\u001b[1;32m    133\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 134\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    135\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import numpy as np\n","import tensorflow as tf\n","\n","from sklearn.model_selection import train_test_split\n","\n","import os\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Flatten,BatchNormalization\n","from tensorflow.keras.layers import Dense, MaxPooling2D,Conv2D\n","from tensorflow.keras.layers import Input,Activation,Add\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","import pandas as pd\n","\n","from keras.models import Sequential,load_model,Model\n","from keras.layers import Conv2D,MaxPool2D,Dense,Dropout,BatchNormalization,Flatten,Input\n","from sklearn.model_selection import train_test_split\n","dataset_folder='/content/drive/MyDrive/Colab Notebooks/CK+48'\n","sub_folders=os.listdir(dataset_folder)\n","\n","sub_folders\n","# Reading folder names as labels and images underneath\n","i=0\n","last=[]\n","images=[]\n","labels=[]\n","temp = sub_folders\n","\n","# reading folders in the main dataset folder, one at a time\n","for sub_folder in sub_folders:\n","  sub_folder_index = temp.index(sub_folder)\n","  label = sub_folder_index\n","\n","  # Define labels basis use case. We are using positive:0, negative:1, neutral:2\n","  # for our use case of predicting emotions of visitors entering a retail store\n","  if  label in [4, 6]:    # label in ['happy', 'surprise']\n","    new_label=0           # changed to label = positive emotion\n","  elif label in [0,5]:      # label in ['anger','sadness']\n","    new_label=1           # changed to label = negative emotion\n","  else:                   # label in ['contempt', 'disgust', 'fear']\n","    new_label=2           # changed to label = neutral emotion\n","\n","\n","  path = dataset_folder+'/'+sub_folder\n","  sub_folder_images= os.listdir(path)\n","\n","  # reading images in the sub folder, one at a time\n","  for image in sub_folder_images:\n","    image_path = path+'/'+image\n","    print(image_path+\"\\t\"+str(new_label))\n","\n","    image = cv2.imread(image_path)\n","    image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","    image= cv2.resize(image,(48,48))\n","    images.append(image)\n","    labels.append(new_label)\n","    i+=1\n","  last.append(i)\n","  images_x = np.array(images)\n","labels_y = np.array(labels)\n","\n","# we divide image pixels by 255 to reduce computation power\n","images_x = images_x/255\n","# encoding the labels\n","num_of_classes = 3\n","labels_y_encoded = tf.keras.utils.to_categorical(labels_y,num_classes=num_of_classes)\n","X_train, X_test, Y_train, Y_test= train_test_split(images_x, labels_y_encoded,test_size=0.25, random_state=10)\n","len(X_train)\n","len(X_test)\n","input = Input(shape = (48,48,1))\n","\n","conv1 = Conv2D(32,(3, 3), padding = 'same', strides=(1, 1), kernel_regularizer=l2(0.001))(input)\n","conv1 = Dropout(0.1)(conv1)\n","conv1 = Activation('relu')(conv1)\n","pool1 = MaxPooling2D(pool_size = (2,2)) (conv1)\n","\n","conv2 = Conv2D(64,(3, 3), padding = 'same', strides=(1, 1), kernel_regularizer=l2(0.001))(pool1)\n","conv2 = Dropout(0.1)(conv2)\n","conv2 = Activation('relu')(conv2)\n","pool2 = MaxPooling2D(pool_size = (2,2)) (conv2)\n","\n","conv3 = Conv2D(128,(3, 3), padding = 'same', strides=(1, 1), kernel_regularizer=l2(0.001))(pool2)\n","conv3 = Dropout(0.1)(conv3)\n","conv3 = Activation('relu')(conv3)\n","pool3 = MaxPooling2D(pool_size = (2,2)) (conv3)\n","\n","conv4 = Conv2D(256,(3, 3), padding = 'same', strides=(1, 1), kernel_regularizer=l2(0.001))(pool3)\n","conv4 = Dropout(0.1)(conv4)\n","conv4 = Activation('relu')(conv4)\n","pool4 = MaxPooling2D(pool_size = (2,2)) (conv4)\n","\n","flatten = Flatten()(pool4)\n","\n","dense_1 = Dense(128,activation='relu')(flatten)\n","\n","drop_1 = Dropout(0.2)(dense_1)\n","\n","output = Dense(3,activation=\"sigmoid\")(drop_1)\n","model = Model(inputs=input,outputs=output)\n","model.compile(optimizer=\"adam\", loss=[\"categorical_crossentropy\"], metrics=['accuracy'])\n","model.summary()\n","fle_s = './output/emotion_model.keras'\n","checkpointer = ModelCheckpoint(fle_s, monitor='loss', verbose=1, save_best_only=True,\n","                               save_weights_only=False, mode='auto', save_freq='epoch')\n","\n","callback_list=[checkpointer]\n","save = model.fit(X_train,Y_train,batch_size=32,validation_data=(X_test,Y_test),epochs=50,callbacks=[callback_list])\n","# Checking the train and test loss and accuracy values from the neural network above.\n","\n","train_loss = save.history['loss']\n","test_loss = save.history['val_loss']\n","train_accuracy = save.history['accuracy']\n","test_accuracy = save.history['val_accuracy']\n","# Plotting a line chart to visualize the loss and accuracy values by epochs.\n","\n","fig, ax = plt.subplots(ncols=2, figsize=(15,7))\n","\n","ax = ax.ravel()\n","\n","ax[0].plot(train_loss, label='Train Loss', color='royalblue', marker='o', markersize=5)\n","ax[0].plot(test_loss, label='Test Loss', color = 'orangered', marker='o', markersize=5)\n","\n","ax[0].set_xlabel('Epochs', fontsize=14)\n","ax[0].set_ylabel('Categorical Crossentropy', fontsize=14)\n","\n","ax[0].legend(fontsize=14)\n","ax[0].tick_params(axis='both', labelsize=12)\n","\n","ax[1].plot(train_accuracy, label='Train Accuracy', color='royalblue', marker='o', markersize=5)\n","ax[1].plot(test_accuracy, label='Test Accuracy', color='orangered', marker='o', markersize=5)\n","\n","ax[1].set_xlabel('Epochs', fontsize=14)\n","ax[1].set_ylabel('Accuracy', fontsize=14)\n","\n","ax[1].legend(fontsize=14)\n","ax[1].tick_params(axis='both', labelsize=12)\n","\n","fig.suptitle(x=0.5, y=0.92, t=\"Lineplots showing loss and accuracy of CNN model by epochs\", fontsize=16)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aLKAiW1iDd6Y"},"outputs":[],"source":["import cv2\n","import numpy as np\n","from tensorflow.keras.models import load_model\n","from tensorflow.keras.preprocessing import image\n","import tensorflow as tf\n","\n","# Load the trained CNN model\n","model = load_model('./output/emotion_model.keras')\n","\n","# Define the emotion labels (you should adjust these based on your training data)\n","emotion_labels = ['Happy', 'Sad', 'Neutral']  # Modify this list based on your training labels\n","\n","# Open the webcam (0 is the default camera)\n","cap = cv2.VideoCapture(0)\n","\n","while True:\n","    # Read frame from the webcam\n","    ret, frame = cap.read()\n","\n","    if not ret:\n","        print(\"Failed to grab frame\")\n","        break\n","\n","    # Convert to grayscale (as the model was trained on grayscale images)\n","    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n","\n","    # Resize the frame to 48x48 (input size expected by your model)\n","    resized_gray = cv2.resize(gray, (48, 48))\n","\n","    # Normalize the pixel values (since the training data was normalized)\n","    normalized_img = resized_gray / 255.0\n","\n","    # Expand dimensions to match the input shape of the model (batch size, height, width, channels)\n","    img_array = np.expand_dims(normalized_img, axis=-1)  # Add the channel dimension\n","    img_array = np.expand_dims(img_array, axis=0)  # Add the batch dimension\n","\n","    # Predict emotion\n","    prediction = model.predict(img_array)\n","    predicted_class = np.argmax(prediction, axis=1)[0]  # Get the index of the highest probability\n","\n","    # Get the corresponding label from the emotion_labels list\n","    predicted_emotion = emotion_labels[predicted_class]\n","\n","    # Display the result on the webcam feed\n","    font = cv2.FONT_HERSHEY_SIMPLEX\n","    cv2.putText(frame, f'Emotion: {predicted_emotion}', (50, 50), font, 1, (255, 0, 0), 2, cv2.LINE_AA)\n","\n","    # Display the frame with the emotion label\n","    cv2.imshow('Emotion Detection', frame)\n","\n","    # Break the loop if 'q' is pressed\n","    if cv2.waitKey(1) & 0xFF == ord('q'):\n","        break\n","\n","# Release the webcam and close all OpenCV windows\n","cap.release()\n","cv2.destroyAllWindows()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nh0TpZnX1ows"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"zOP5M5We-5oz"},"source":["**SVM** **Algorithm**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OG5y0Tks-5Za"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xtgHn3i7gZ1q"},"outputs":[],"source":["\n","\n","import numpy as np\n","import os\n","import cv2\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.svm import SVC\n","from sklearn.metrics import classification_report\n","import matplotlib.pyplot as plt\n","\n","# Load dataset\n","dataset_folder = '/content/drive/MyDrive/Colab Notebooks/CK+48'\n","sub_folders = os.listdir(dataset_folder)\n","\n","images = []\n","labels = []\n","\n","for sub_folder in sub_folders:\n","    label = sub_folder\n","    path = dataset_folder + '/' + sub_folder\n","    sub_folder_images = os.listdir(path)\n","\n","    for image in sub_folder_images:\n","        image_path = path + '/' + image\n","        img = cv2.imread(image_path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","        img = cv2.resize(img, (48, 48))\n","        images.append(img)\n","        labels.append(label)\n","\n","# Convert to numpy arrays\n","images_x = np.array(images) / 255.0\n","labels_y = np.array(labels)\n","\n","# Flatten images for SVM\n","images_x_flat = images_x.reshape(images_x.shape[0], -1)\n","\n","# Encode labels\n","lb = LabelBinarizer()\n","labels_y_encoded = lb.fit_transform(labels_y).argmax(axis=1)\n","\n","# Split dataset\n","X_train, X_test, Y_train, Y_test = train_test_split(images_x_flat, labels_y_encoded, test_size=0.25, random_state=10)\n","\n","# SVM Model\n","svm_model = SVC(kernel='rbf', C=1, gamma='scale')\n","svm_model.fit(X_train, Y_train)\n","\n","# Predictions\n","Y_pred = svm_model.predict(X_test)\n","\n","# Evaluation: Classification Report\n","print(\"Classification Report:\")\n","print(classification_report(Y_test, Y_pred, target_names=lb.classes_))\n","\n","# Accuracy Plot: Since SVM does not use epochs, we will just plot accuracy as a bar\n","accuracy = np.mean(Y_pred == Y_test) * 100\n","\n","\n","# Optional: If you want to visualize a training \"loss curve\", we can't plot one directly for SVM.\n","# However, if you'd like to simulate it, we can use cross-validation to get some \"iterations\" and accuracy.\n","\n","# For demonstration, using the cross-validation scores (this isn't a loss curve, but accuracy at different splits)\n","from sklearn.model_selection import cross_val_score\n","svm_model_cv = SVC(kernel='rbf', C=1, gamma='scale')\n","cv_scores = cross_val_score(svm_model_cv, X_train, Y_train, cv=5)\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wvT4B5DU-Uh_"},"source":[]},{"cell_type":"markdown","metadata":{"id":"64xpjAji_mcU"},"source":["**KNN** **Algorithm**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eAX4ckXm6BOR"},"outputs":[],"source":["from google.colab import drive\n","import numpy as np\n","import os\n","import cv2\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.metrics import classification_report\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import cross_val_score\n","\n","# Load dataset\n","dataset_folder = '/content/drive/MyDrive/Colab Notebooks/CK+48'\n","sub_folders = os.listdir(dataset_folder)\n","\n","images = []\n","labels = []\n","\n","for sub_folder in sub_folders:\n","    label = sub_folder\n","    path = dataset_folder + '/' + sub_folder\n","    sub_folder_images = os.listdir(path)\n","\n","    for image in sub_folder_images:\n","        image_path = path + '/' + image\n","        img = cv2.imread(image_path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","        img = cv2.resize(img, (48, 48))\n","        images.append(img)\n","        labels.append(label)\n","\n","# Convert to numpy arrays\n","images_x = np.array(images) / 255.0\n","labels_y = np.array(labels)\n","\n","# Flatten images for KNN\n","images_x_flat = images_x.reshape(images_x.shape[0], -1)\n","\n","# Encode labels\n","lb = LabelBinarizer()\n","labels_y_encoded = lb.fit_transform(labels_y).argmax(axis=1)\n","\n","# Split dataset\n","X_train, X_test, Y_train, Y_test = train_test_split(images_x_flat, labels_y_encoded, test_size=0.25, random_state=10)\n","\n","# KNN Model\n","knn_model = KNeighborsClassifier(n_neighbors=3)\n","knn_model.fit(X_train, Y_train)\n","\n","# Predictions\n","Y_pred = knn_model.predict(X_test)\n","\n","# Evaluation: Classification Report\n","print(\"KNN Classification Report:\")\n","print(classification_report(Y_test, Y_pred, target_names=lb.classes_))\n","\n","# Accuracy Plot\n","accuracy = np.mean(Y_pred == Y_test) * 100\n","\n","\n","# Cross-validation to simulate \"epochs\" and accuracy for different splits\n","cv_scores = cross_val_score(knn_model, X_train, Y_train, cv=5)\n","\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8eftUp846dqs"},"outputs":[],"source":["from google.colab import drive\n","import numpy as np\n","import os\n","import cv2\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelBinarizer\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import cross_val_score\n","\n","# Load dataset\n","dataset_folder = '/content/drive/MyDrive/Colab Notebooks/CK+48'\n","sub_folders = os.listdir(dataset_folder)\n","\n","images = []\n","labels = []\n","\n","for sub_folder in sub_folders:\n","    label = sub_folder\n","    path = dataset_folder + '/' + sub_folder\n","    sub_folder_images = os.listdir(path)\n","\n","    for image in sub_folder_images:\n","        image_path = path + '/' + image\n","        img = cv2.imread(image_path)\n","        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","        img = cv2.resize(img, (48, 48))\n","        images.append(img)\n","        labels.append(label)\n","\n","# Convert to numpy arrays\n","images_x = np.array(images) / 255.0\n","labels_y = np.array(labels)\n","\n","# Flatten images for Random Forest\n","images_x_flat = images_x.reshape(images_x.shape[0], -1)\n","\n","# Encode labels\n","lb = LabelBinarizer()\n","labels_y_encoded = lb.fit_transform(labels_y).argmax(axis=1)\n","\n","# Split dataset\n","X_train, X_test, Y_train, Y_test = train_test_split(images_x_flat, labels_y_encoded, test_size=0.25, random_state=10)\n","\n","# Random Forest Model\n","rf_model = RandomForestClassifier(n_estimators=100, random_state=10)\n","rf_model.fit(X_train, Y_train)\n","\n","# Predictions\n","Y_pred = rf_model.predict(X_test)\n","\n","# Evaluation: Classification Report\n","print(\"Random Forest Classification Report:\")\n","print(classification_report(Y_test, Y_pred, target_names=lb.classes_))\n","\n","# Accuracy Plot\n","accuracy = np.mean(Y_pred == Y_test) * 100\n","\n","# Cross-validation to simulate \"epochs\" and accuracy for different splits\n","cv_scores = cross_val_score(rf_model, X_train, Y_train, cv=5)\n","\n","# Plotting Cross-Validation Scores\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VEVP5aIW_A7S"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MmVWUoPq7Sx7"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","import numpy as np\n","import tensorflow as tf\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import classification_report\n","\n","import os\n","import cv2\n","from google.colab.patches import cv2_imshow\n","import matplotlib.pyplot as plt\n","\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import Flatten, BatchNormalization\n","from tensorflow.keras.layers import Dense, MaxPooling2D, Conv2D\n","from tensorflow.keras.layers import Input, Activation, Add\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.regularizers import l2\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.callbacks import ModelCheckpoint\n","\n","import pandas as pd\n","\n","from keras.models import Sequential, load_model, Model\n","from keras.layers import Conv2D, MaxPool2D, Dense, Dropout, BatchNormalization, Flatten, Input\n","from sklearn.model_selection import train_test_split\n","\n","# Set dataset folder path\n","dataset_folder = '/content/drive/MyDrive/Colab Notebooks/CK+48'\n","sub_folders = os.listdir(dataset_folder)\n","\n","# Reading folder names as labels and images underneath\n","i = 0\n","last = []\n","images = []\n","labels = []\n","temp = sub_folders\n","\n","# reading folders in the main dataset folder, one at a time\n","for sub_folder in sub_folders:\n","    sub_folder_index = temp.index(sub_folder)\n","    label = sub_folder_index\n","\n","    # Define labels based on use case\n","    if label in [4, 6]:  # happy, surprise\n","        new_label = 0  # positive emotion\n","    elif label in [0, 5]:  # anger, sadness\n","        new_label = 1  # negative emotion\n","    else:  # contempt, disgust, fear\n","        new_label = 2  # neutral emotion\n","\n","    path = dataset_folder + '/' + sub_folder\n","    sub_folder_images = os.listdir(path)\n","\n","    # Reading images in the sub-folder, one at a time\n","    for image in sub_folder_images:\n","        image_path = path + '/' + image\n","        print(image_path + \"\\t\" + str(new_label))\n","\n","        image = cv2.imread(image_path)\n","        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n","        image = cv2.resize(image, (48, 48))\n","        images.append(image)\n","        labels.append(new_label)\n","        i += 1\n","    last.append(i)\n","    images_x = np.array(images)\n","\n","labels_y = np.array(labels)\n","\n","# Normalizing image data\n","images_x = images_x / 255.0\n","\n","# Encoding the labels\n","num_of_classes = 3\n","labels_y_encoded = tf.keras.utils.to_categorical(labels_y, num_classes=num_of_classes)\n","\n","# Splitting the data into training and testing sets\n","X_train, X_test, Y_train, Y_test = train_test_split(images_x, labels_y_encoded, test_size=0.25, random_state=10)\n","\n","# Defining the model architecture\n","input = Input(shape=(48, 48, 1))\n","\n","conv1 = Conv2D(32, (3, 3), padding='same', strides=(1, 1), kernel_regularizer=l2(0.001))(input)\n","conv1 = Dropout(0.1)(conv1)\n","conv1 = Activation('relu')(conv1)\n","pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","\n","conv2 = Conv2D(64, (3, 3), padding='same', strides=(1, 1), kernel_regularizer=l2(0.001))(pool1)\n","conv2 = Dropout(0.1)(conv2)\n","conv2 = Activation('relu')(conv2)\n","pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","\n","conv3 = Conv2D(128, (3, 3), padding='same', strides=(1, 1), kernel_regularizer=l2(0.001))(pool2)\n","conv3 = Dropout(0.1)(conv3)\n","conv3 = Activation('relu')(conv3)\n","pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","\n","conv4 = Conv2D(256, (3, 3), padding='same', strides=(1, 1), kernel_regularizer=l2(0.001))(pool3)\n","conv4 = Dropout(0.1)(conv4)\n","conv4 = Activation('relu')(conv4)\n","pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n","\n","flatten = Flatten()(pool4)\n","\n","dense_1 = Dense(128, activation='relu')(flatten)\n","\n","drop_1 = Dropout(0.2)(dense_1)\n","\n","output = Dense(3, activation=\"sigmoid\")(drop_1)\n","\n","# Compiling the model\n","model = Model(inputs=input, outputs=output)\n","model.compile(optimizer=\"adam\", loss=[\"categorical_crossentropy\"], metrics=['accuracy'])\n","model.summary()\n","\n","# Define the callback for saving the best model\n","fle_s = './output/emotion_model.keras'\n","checkpointer = ModelCheckpoint(fle_s, monitor='loss', verbose=1, save_best_only=True,\n","                               save_weights_only=False, mode='auto', save_freq='epoch')\n","\n","callback_list = [checkpointer]\n","\n","# Train the model\n","save = model.fit(X_train, Y_train, batch_size=32, validation_data=(X_test, Y_test), epochs=50, callbacks=[callback_list])\n","\n","# Plotting loss and accuracy\n","train_loss = save.history['loss']\n","test_loss = save.history['val_loss']\n","train_accuracy = save.history['accuracy']\n","test_accuracy = save.history['val_accuracy']\n","\n","fig, ax = plt.subplots(ncols=2, figsize=(15, 7))\n","ax = ax.ravel()\n","\n","ax[0].plot(train_loss, label='Train Loss', color='royalblue', marker='o', markersize=5)\n","ax[0].plot(test_loss, label='Test Loss', color='orangered', marker='o', markersize=5)\n","ax[0].set_xlabel('Epochs', fontsize=14)\n","ax[0].set_ylabel('Categorical Crossentropy', fontsize=14)\n","ax[0].legend(fontsize=14)\n","ax[0].tick_params(axis='both', labelsize=12)\n","\n","ax[1].plot(train_accuracy, label='Train Accuracy', color='royalblue', marker='o', markersize=5)\n","ax[1].plot(test_accuracy, label='Test Accuracy', color='orangered', marker='o', markersize=5)\n","ax[1].set_xlabel('Epochs', fontsize=14)\n","ax[1].set_ylabel('Accuracy', fontsize=14)\n","ax[1].legend(fontsize=14)\n","ax[1].tick_params(axis='both', labelsize=12)\n","\n","fig.suptitle(x=0.5, y=0.92, t=\"Lineplots showing loss and accuracy of CNN model by epochs\", fontsize=16)\n","\n","# Generate predictions for both training and test sets\n","train_predictions = model.predict(X_train)\n","test_predictions = model.predict(X_test)\n","\n","# Convert the predictions from probabilities to class labels (0, 1, or 2)\n","train_predictions = np.argmax(train_predictions, axis=1)\n","test_predictions = np.argmax(test_predictions, axis=1)\n","\n","# Convert the true labels back to class labels\n","train_true_labels = np.argmax(Y_train, axis=1)\n","test_true_labels = np.argmax(Y_test, axis=1)\n","\n","# Classification report for the training set\n","train_classification_report = classification_report(train_true_labels, train_predictions, target_names=['Positive', 'Negative', 'Neutral'])\n","print(\"Training Classification Report:\\n\")\n","print(train_classification_report)\n","\n","# Classification report for the test set\n","test_classification_report = classification_report(test_true_labels, test_predictions, target_names=['Positive', 'Negative', 'Neutral'])\n","print(\"\\nTesting Classification Report:\\n\")\n","print(test_classification_report)\n","\n","# Overall classification report for the entire dataset\n","# Combining both training and test labels\n","all_true_labels = np.concatenate((train_true_labels, test_true_labels))\n","all_predictions = np.concatenate((train_predictions, test_predictions))\n","\n","overall_classification_report = classification_report(all_true_labels, all_predictions, target_names=['Positive', 'Negative', 'Neutral'])\n","print(\"\\nOverall Classification Report:\\n\")\n","print(overall_classification_report)\n"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[{"file_id":"/v2/external/notebooks/intro.ipynb","timestamp":1733306007543}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}